### THIS FILE IS AUTOGENERATED. DO NOT EDIT THIS FILE DIRECTLY ###
from .statistics_pb2_grpc import *
from . import statistics_pb2
from minLights.rpc.statistics_pb2 import *
from minLights.rpc._support import MessageWrapper, ArgumentError
import time
import logging

__all__ = [
    "StatisticsService",
    "StreamDutyTimeRequest",
    "StreamDutyTimeResponse",
    "GetDutyTimeRequest",
    "GetDutyTimeResponse",
    "StreamReadLengthHistogramRequest",
    "ReadLengthHistogramData",
    "N50Data",
    "StreamReadLengthHistogramResponse",
    "GetReadLengthHistogramRequest",
    "GetReadLengthHistogramResponse",
    "GetReadLengthTypesRequest",
    "GetReadLengthTypesResponse",
    "StreamHeatmapRequest",
    "StreamHeatmapResponse",
    "StreamCumulativeThroughputRequest",
    "CumulativeThroughputBucket",
    "StreamCumulativeThroughputResponse",
    "GetCumulativeThroughputRequest",
    "GetCumulativeThroughputResponse",
    "StreamPerBarcodeCumulativeThroughputRequest",
    "CumulativeThroughputBucketVector",
    "StreamPerBarcodeCumulativeThroughputResponse",
    "GetPerBarcodeCumulativeThroughputRequest",
    "GetPerBarcodeCumulativeThroughputResponse",
    "StreamEncounteredBarcodeNamesRequest",
    "StreamEncounteredBarcodeNamesResponse",
    "GetEncounteredBarcodeNamesRequest",
    "GetEncounteredBarcodeNamesResponse",
    "StreamTemperatureRequest",
    "TemperaturePacket",
    "StreamTemperatureResponse",
    "GetTemperatureRequest",
    "GetTemperatureResponse",
    "BiasVoltagePacket",
    "StreamBiasVoltagesRequest",
    "StreamBiasVoltagesResponse",
    "GetBiasVoltagesRequest",
    "GetBiasVoltagesResponse",
    "GetBoxplotRequest",
    "StreamBoxplotRequest",
    "BoxplotResponse",
    "TimeUnit",
    "SECONDS",
    "MINUTES",
    "BucketValueType",
    "READ_COUNTS",
    "READ_LENGTHS",
    "ReadLengthType",
    "EVENTS",
    "ESTIMATED_BASES",
    "BASECALLED_BASES",
]

class StatisticsService(object):
    def __init__(self, channel):
        self._stub = StatisticsServiceStub(channel)
        self._pb = statistics_pb2

    def stream_duty_time(self, _message=None, _timeout=None, **kwargs):
        """
        Tracks how much time has been spent in each channel state, aggregated across all the channels

        Will fail with FAILED_PRECONDITION if minknow is not acquiring data unless `wait_for_processing` is set to True,
        then it will block and wait for data to start acquiring.

        The first response will give you all the data it can

        Since 1.13

        :param step: (required)
            Defines (in seconds) the bucket period of the duty time data

            Will fail with INVALID_ARGUMENT if `step` is below 60
            Will fail with INVALID_ARGUMENT if `step` is not a multiple of 60
            TODO: maximum size?
        :param start_time:
            Specify the start time of the data since the start time of the experiment (in seconds). If not specified then will return data since the start of the experiment

            Will fail with INVALID_ARGUMENT if not a multiple of `step`. (TODO: maybe round to closest value instead of failing?)

            For example, if this was set to 600 with a step of 60, then the first 10 buckets will not be returned
            and the first bucket will be [600,660)
        :param end_time:
            Specify the end time of the data (in seconds). Call will return if the end time has been reached.
            If the end time has not yet been reached, then the stream will continue until it has, and then return.
            If not specified, then will stream forever
            If `end_time` is 0, then this will count as not specified and will stream forever

            Will fail with INVALID_ARGUMENT if not a multiple of `step`
            Will fail with INVALID_ARGUMENT if not more than `start_time`

            This specifies T1 for a bucket [T0, T1)
        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead
            of returning with an error

            Defaults to false
        :rtype: StreamDutyTimeResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_duty_time(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_duty_time. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamDutyTimeRequest()

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("stream_duty_time requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if len(unused_args) > 0:
            raise ArgumentError("stream_duty_time got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_duty_time(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_duty_time. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_duty_time(self, _message=None, _timeout=None, **kwargs):
        """
        Gets duty time information for a completed acquisition period.

        Currently, all time values must be given in multiples of 1 minute (it is recommended that the
        time unit is set to minutes).

        Since 1.14

        :param run_id: (required)
            The acquisition id of the experiment.
        :param step: (required)
            Defines the bucket period of the duty time data, in multiples of `time_unit`.
        :param start_time:
            Specify the start time of the data since the start time of the experiment in multiples of
            `time_unit`.

            Must be a multiple of `step`.

            If not specified then will return data since the start of the experiment.
        :param end_time:
            Specify the end time of the data to return in multiples of `time_unit`. Only data from before
            this time will be returned.

            This does not need to be a multiple of `step` - you will get a smaller final bucket if it is
            not.

            If not specified then will return all the data till the end of the experiment.
            A time past the end of the experiment will be accepted, and treated in the same way.
        :param time_unit:
            What unit of time to use. Defaults to SECONDS

            This is used to interpret the other fields in this message as well as for the times in the
            response message.
        :rtype: GetDutyTimeResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_duty_time(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_duty_time. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetDutyTimeRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_duty_time requires a 'run_id' argument")

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("get_duty_time requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'time_unit' in kwargs:
            unused_args.remove('time_unit')
            _message.time_unit = kwargs['time_unit']

        if len(unused_args) > 0:
            raise ArgumentError("get_duty_time got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_duty_time(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_duty_time. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_throughput(self, _message=None, _timeout=None, **kwargs):
        """
        Tracks experiment throughput across all channels over time

        The first response will give you all the data it can.

        The stream will end once the current acquisition period ends, and a caller will need to
        reinvoke the rpc in order to get new throughput data.

        Since 1.14

        :param step: (required)
            Defines (in seconds) the bucket period of the throughput

            The minimum size for `step` is 60
            TODO: maximum size?
        :param start_time:
            Specify the start time of the throughput data (in seconds). If not specified then will return data since the start of the experiment

            Will fail with INVALID_ARGUMENT if not a multiple of `step`. (TODO: maybe round to closest value instead of failing?)

            For example, if this was set to 600 with a step of 60, then the first 10 buckets will not be returned
            and the first bucket will be [600,660)
        :param end_time:
            Specify the end time of the data (in seconds). Call will return if the end time has been reached.
            If the end time has not yet been reached, then the stream will continue until it has, and then return.
            If not specified, then will stream forever

            Will fail with INVALID_ARGUMENT if not a multiple of `step`
            Will fail with INVALID_ARGUMENT if not more than `start_time`

            This specifies T1 for a bucket [T0, T1)
        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead of returning with an error

            Defaults to false
        :rtype: StreamCumulativeThroughputResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_throughput(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamCumulativeThroughputRequest()

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("stream_throughput requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if len(unused_args) > 0:
            raise ArgumentError("stream_throughput got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_throughput(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_throughput(self, _message=None, _timeout=None, **kwargs):
        """
        Gets cumultative throughput information for a completed acquisition period.

        Currently, all time values must be given in multiples of 1 minute (it is recommended that the
        time unit is set to minutes).

        Since 1.14

        :param run_id: (required)
            The acquisition id of the experiment.
        :param step: (required)
            Defines the bucket period of the cumulative throughput data, in multiples of `time_unit`.
        :param start_time:
            Specify the start time of the data since the start time of the experiment in multiples of
            `time_unit`.

            Must be a multiple of `step`.

            If not specified then will return data since the start of the experiment.
        :param end_time:
            Specify the end time of the data to return in multiples of `time_unit`. Only data from before
            this time will be returned.

            This does not need to be a multiple of `step` - you will get a smaller final bucket if it is
            not.

            If not specified then will return all the data till the end of the experiment.
            A time past the end of the experiment will be accepted, and treated in the same way.
        :param time_unit:
            What unit of time to use. Defaults to SECONDS

            This is used to interpret the other fields in this message as well as for the times in the
            response message.
        :rtype: GetCumulativeThroughputResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_throughput(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetCumulativeThroughputRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_throughput requires a 'run_id' argument")

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("get_throughput requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'time_unit' in kwargs:
            unused_args.remove('time_unit')
            _message.time_unit = kwargs['time_unit']

        if len(unused_args) > 0:
            raise ArgumentError("get_throughput got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_throughput(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_per_barcode_throughput(self, _message=None, _timeout=None, **kwargs):
        """
        Tracks per-barcode throughput across all channels over time

        The first response will give you all the data it can.

        The stream will end once the current acquisition period ends, and a caller will need to
        reinvoke the rpc in order to get new throughput data.

        Since 3.6

        :param step: (required)
            Defines (in seconds) the bucket period of the throughput

            The minimum size for `step` is 60
        :param start_time:
            Specify the start time of the throughput data (in seconds). If not specified then will return data since the start of the experiment

            Will fail with INVALID_ARGUMENT if not a multiple of `step`.

            For example, if this was set to 600 with a step of 60, then the first 10 buckets will not be returned
            and the first bucket will be [600,660)
        :param end_time:
            Specify the end time of the data (in seconds). Call will return if the end time has been reached.
            If the end time has not yet been reached, then the stream will continue until it has, and then return.
            If not specified, then will stream forever.

            Will fail with INVALID_ARGUMENT if not a multiple of `step`
            Will fail with INVALID_ARGUMENT if not more than `start_time`

            This specifies T1 for a bucket [T0, T1)
        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead of returning with an error

            Defaults to false
        :param barcodes:
            What barcode names to return data for
            If no barcode names are specified, then data for all barcode names is returned
        :rtype: StreamPerBarcodeCumulativeThroughputResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_per_barcode_throughput(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_per_barcode_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamPerBarcodeCumulativeThroughputRequest()

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("stream_per_barcode_throughput requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if 'barcodes' in kwargs:
            unused_args.remove('barcodes')
            _message.barcodes.extend(kwargs['barcodes'])

        if len(unused_args) > 0:
            raise ArgumentError("stream_per_barcode_throughput got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_per_barcode_throughput(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_per_barcode_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_per_barcode_throughput(self, _message=None, _timeout=None, **kwargs):
        """
        Gets per-barcode cumultative throughput information for a completed acquisition period.

        Currently, all time values must be given in multiples of 1 minute (it is recommended that the
        time unit is set to minutes).

        Since 3.6

        :param run_id: (required)
            The acquisition id of the experiment.
        :param step: (required)
            Defines the bucket period of the cumulative throughput data, in multiples of `time_unit`.
        :param start_time:
            Specify the start time of the data since the start time of the experiment in multiples of
            `time_unit`.

            Must be a multiple of `step`.

            If not specified then will return data since the start of the experiment.
        :param end_time:
            Specify the end time of the data to return in multiples of `time_unit`. Only data from before
            this time will be returned.

            This does not need to be a multiple of `step` - you will get a smaller final bucket if it is
            not.

            If not specified then will return all the data till the end of the experiment.
            A time past the end of the experiment will be accepted, and treated in the same way.
        :param time_unit:
            What unit of time to use. Defaults to SECONDS

            This is used to interpret the other fields in this message as well as for the times in the
            response message.
        :param barcodes:
            What barcode names to return data for
            If no barcode names are specified, then data for all barcode names is returned
        :rtype: GetPerBarcodeCumulativeThroughputResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_per_barcode_throughput(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_per_barcode_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetPerBarcodeCumulativeThroughputRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_per_barcode_throughput requires a 'run_id' argument")

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("get_per_barcode_throughput requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'time_unit' in kwargs:
            unused_args.remove('time_unit')
            _message.time_unit = kwargs['time_unit']

        if 'barcodes' in kwargs:
            unused_args.remove('barcodes')
            _message.barcodes.extend(kwargs['barcodes'])

        if len(unused_args) > 0:
            raise ArgumentError("get_per_barcode_throughput got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_per_barcode_throughput(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_per_barcode_throughput. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_encountered_barcode_names(self, _message=None, _timeout=None, **kwargs):
        """
        Tracks which barcode names have been encountered

        When a new barcode name is encountered, a list of all encountered barcode names is returned

        Since 3.6

        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead of returning with an error

            Defaults to false
        :rtype: StreamEncounteredBarcodeNamesResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_encountered_barcode_names(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_encountered_barcode_names. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamEncounteredBarcodeNamesRequest()

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if len(unused_args) > 0:
            raise ArgumentError("stream_encountered_barcode_names got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_encountered_barcode_names(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_encountered_barcode_names. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_encountered_barcode_names(self, _message=None, _timeout=None, **kwargs):
        """
        Gets the barcode names which were encountered

        Since 3.6

        :param run_id: (required)
            The acquisition id of the experiment.
        :rtype: GetEncounteredBarcodeNamesResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_encountered_barcode_names(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_encountered_barcode_names. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetEncounteredBarcodeNamesRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_encountered_barcode_names requires a 'run_id' argument")

        if len(unused_args) > 0:
            raise ArgumentError("get_encountered_barcode_names got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_encountered_barcode_names(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_encountered_barcode_names. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_temperature(self, _message=None, _timeout=None, **kwargs):
        """
        Streams device temperature for a device. The first message will contain all of the temperatures up
        until the current live point, and then messages after that point will just be updates.

        Temperatures are averaged over a 1 minute period, and the value of each bucket is given in minute intervals

        Since 3.0

        :param step: (required)
            Defines the bucket period of the temperatures in terms of `time_unit`

            Will fail with INVALID_ARGUMENT if the value is below 1 minute (or equivalent in another time unit)
        :param start_time:
            Specify the inclusive start time of the data since the start of the experiment in multiples of
            `time_unit`. If not specified then will return data since the start of the experiment

            Will fail with INVALID_ARGUMENT if not a multiple of `step`. (TODO: maybe round to closest value instead of failing?)

            For example, if this was set to 600 with a step of 60, then the first 10 buckets will not be returned
            and the first bucket will be [600,660)
        :param end_time:
            Specify the exclusive end time of the data to return in multiples of `time_unit`. Only data from before
            this time will be returned.

            Call will return if the end time has been reached.
            If the end time has not yet been reached, then the stream will continue until it has, and then return.
            If not specified, then will stream forever

            Will fail with INVALID_ARGUMENT if not a multiple of `step`
            Will fail with INVALID_ARGUMENT if not more than `start_time`
        :param wait_for_starting:
            If `wait_for_starting` is true, then will wait until minknow begins an acquisition period instead of returning with
            an error

            Defaults to false
        :param time_unit:
            What unit of time to use. Defaults to SECONDS

            This is used to interpret the other fields in this message as well as for the times in the
            response message.
        :rtype: StreamTemperatureResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_temperature(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_temperature. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamTemperatureRequest()

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("stream_temperature requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'wait_for_starting' in kwargs:
            unused_args.remove('wait_for_starting')
            _message.wait_for_starting = kwargs['wait_for_starting']

        if 'time_unit' in kwargs:
            unused_args.remove('time_unit')
            _message.time_unit = kwargs['time_unit']

        if len(unused_args) > 0:
            raise ArgumentError("stream_temperature got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_temperature(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_temperature. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_temperature(self, _message=None, _timeout=None, **kwargs):
        """
        Gets the history for device temperature for a particular acquisition period

        Will fail with INVALID_ARGUMENT if an unknown acquisition id is given

        Since 3.1

        :param run_id: (required)
            The acquisition id of the experiment.
        :param step: (required)
            Defines the bucket period of the cumulative throughput data, in multiples of `time_unit`.
        :param start_time:
            Specify the start time of the data since the start time of the experiment in multiples of
            `time_unit`.

            Must be a multiple of `step`.

            If not specified then will return data since the start of the experiment.
        :param end_time:
            Specify the end time of the data to return in multiples of `time_unit`. Only data from before
            this time will be returned.

            This does not need to be a multiple of `step` - you will get a smaller final bucket if it is
            not.

            If not specified then will return all the data till the end of the experiment.
            A time past the end of the experiment will be accepted, and treated in the same way.
        :param time_unit:
            What unit of time to use. Defaults to SECONDS

            This is used to interpret the other fields in this message as well as for the times in the
            response message.
        :rtype: GetTemperatureResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_temperature(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_temperature. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetTemperatureRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_temperature requires a 'run_id' argument")

        if 'step' in kwargs:
            unused_args.remove('step')
            _message.step = kwargs['step']
        else:
            raise ArgumentError("get_temperature requires a 'step' argument")

        if 'start_time' in kwargs:
            unused_args.remove('start_time')
            _message.start_time = kwargs['start_time']

        if 'end_time' in kwargs:
            unused_args.remove('end_time')
            _message.end_time = kwargs['end_time']

        if 'time_unit' in kwargs:
            unused_args.remove('time_unit')
            _message.time_unit = kwargs['time_unit']

        if len(unused_args) > 0:
            raise ArgumentError("get_temperature got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_temperature(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_temperature. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_bias_voltages(self, _message=None, _timeout=None, **kwargs):
        """
        Streams when bias voltage changes occur, where the response given will be the acquisition
        index that the voltage changed at, and the voltage itself. The first message will contain
        all of the bias voltage changes up until the current live point, and then messages after
        that period will just be updates

        Will fail with INVALID_ARGUMENT if an unknown acquisition id is given

        Since 3.2

        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead
            of returning with an error

            Defaults to false
        :rtype: StreamBiasVoltagesResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_bias_voltages(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_bias_voltages. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamBiasVoltagesRequest()

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if len(unused_args) > 0:
            raise ArgumentError("stream_bias_voltages got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_bias_voltages(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_bias_voltages. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_bias_voltages(self, _message=None, _timeout=None, **kwargs):
        """
        Gets the history of bias volatge changes for a particular acquisition period

        Will fail with INVALID_ARGUMENT if an unknown acquisition id is given

        Since 3.2

        :param run_id: (required)
            The acquisition id of the experiment.
        :rtype: GetBiasVoltagesResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_bias_voltages(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_bias_voltages. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetBiasVoltagesRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_bias_voltages requires a 'run_id' argument")

        if len(unused_args) > 0:
            raise ArgumentError("get_bias_voltages got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_bias_voltages(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_bias_voltages. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_read_length_histogram(self, _message=None, _timeout=None, **kwargs):
        """
        A histogram of estimated read lengths (based on events)

        A whole new histogram will be sent everytime minknow polls for data (set by `poll_time`) and not just updates

        Since 3.0

        :param bucket_width:
            Sets the desired width of the buckets, in terms of the requested read length type.
            The actual width of bins in the returned histogram may not be the number set here.

            If not set, then will set the minimum width possible
        :param start:
            Sets the point of the leftmost bucket, in terms of the requested read length type.

            The leftmost bucket of the upscaled histogram will be the one that contains this value.
            The histogram will contain data for values starting at the minimum value for this bucket.
            Thus, the start value of the histogram may be lower than the value specified by this
            field.

            By default will start from 0
        :param end:
            Sets the point of the rightmost bucket, in terms of the requested read length type.

            If a non-zero value is specified, then the rightmost bucket of the upscaled histogram will be the one that contains this value.
            The histogram will contain data for values ending at the maximum value for this bucket.
            Thus, the end value of the histogram may be higher than the value specified by this
            field.

            If zero is specified, then the rightmost bucket will be the highest one which has data stored in it.
            This will be freshly determined with every streamed response.
            This means that the number of buckets can shrink or grow between 2 responses.

            Be default, this will be 0
        :param bucket_value_type:
            Determines what type of value is in the buckets - counts or lengths.

            See `BucketValueType` definition for a concrete example of what each type represents.
        :param poll_time:
            Sets how long minknow will take to poll the data and return a response, specified
            in [time_unit]
        :param time_unit:
            What unit of time are to use. Defaults to SECONDS

            This is used to interpret the other fields in this message as well as for the times in the
            response message.
        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead
            of returning with an error

            Defaults to false
        :param read_length_type:
            Determines how to measure read lengths

            See `ReadLengthType` definition for a concrete example of what each type represents.
            If MinKNOW is unable to calculate the requested measurement, it will fall back to
            supplying data of a type it can calculate; the response will contain a field specifying
            the type of data actually calculated.
        :param discard_outlier_percent:
            If set greater than zero then discard some percent of long reads at the upper
            end of the histogram, before calculating the histogram buckets.

            This is intended to assist with a few very long reads confusing the histogram axes.

            Defaults to 0 - no reads discarded - values should be specified in percent - a value of 0.05
            will filter 5% of reads from the upper end of the histogram.

            Since 3.6
        :rtype: StreamReadLengthHistogramResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_read_length_histogram(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_read_length_histogram. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamReadLengthHistogramRequest()

        if 'bucket_width' in kwargs:
            unused_args.remove('bucket_width')
            _message.bucket_width = kwargs['bucket_width']

        if 'start' in kwargs:
            unused_args.remove('start')
            _message.start = kwargs['start']

        if 'end' in kwargs:
            unused_args.remove('end')
            _message.end = kwargs['end']

        if 'bucket_value_type' in kwargs:
            unused_args.remove('bucket_value_type')
            _message.bucket_value_type = kwargs['bucket_value_type']

        if 'poll_time' in kwargs:
            unused_args.remove('poll_time')
            _message.poll_time = kwargs['poll_time']

        if 'time_unit' in kwargs:
            unused_args.remove('time_unit')
            _message.time_unit = kwargs['time_unit']

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if 'read_length_type' in kwargs:
            unused_args.remove('read_length_type')
            _message.read_length_type = kwargs['read_length_type']

        if 'discard_outlier_percent' in kwargs:
            unused_args.remove('discard_outlier_percent')
            _message.discard_outlier_percent = kwargs['discard_outlier_percent']

        if len(unused_args) > 0:
            raise ArgumentError("stream_read_length_histogram got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_read_length_histogram(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_read_length_histogram. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_read_length_histogram(self, _message=None, _timeout=None, **kwargs):
        """
        Gets the estimated read lengths for a particular acquisition period

        Since 3.0

        :param run_id: (required)
            The acquisition id of the experiment
        :param bucket_width:
            Sets the desired width of the buckets, in terms of the requested read length type.
            The actual width of bins in the returned histogram may not be the number set here.

            If not set, then will set the minimum width possible
        :param start:
            Sets the point of the leftmost bucket, in terms of the requested read length type.

            The leftmost bucket of the upscaled histogram will be the one that contains this value.
            The histogram will contain data for values starting at the minimum value for this bucket.
            Thus, the start value of the histogram may be lower than the value specified by this
            field.

            By default will start from 0
        :param end:
            Sets the point of the rightmost bucket, in terms of the requested read length type.

            If a non-zero value is specified, then the rightmost bucket of the upscaled histogram will be the one that contains this value.
            The histogram will contain data for values ending at the maximum value for this bucket.
            Thus, the end value of the histogram may be higher than the value specified by this
            field.

            If zero is specified, then the rightmost bucket will be the highest one which has data stored in it.

            Be default, this will be 0
        :param bucket_value_type:
            Determines what type of value is in the buckets - counts or lengths.

            See `BucketValueType` definition for a concrete example of what each type represents.
        :param read_length_type:
            Determines how to measure read lengths

            See `ReadLengthType` definition for a concrete example of what each type represents.
            If MinKNOW is unable to calculate the requested measurement, it will fall back to
            supplying data of a type it can calculate; the response will contain a field specifying
            the type of data actually calculated.
        :param discard_outlier_percent:
            If set greater than zero then discard some percent of long reads at the upper
            end of the histogram, before calculating the histogram buckets.

            This is intended to assist with a few very long reads confusing the histogram axes.

            Defaults to 0 - no reads discarded - values should be specified in percent - a value of 0.05
            will filter 5% of reads from the upper end of the histogram.

            Since 3.6
        :rtype: GetReadLengthHistogramResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_read_length_histogram(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_read_length_histogram. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetReadLengthHistogramRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_read_length_histogram requires a 'run_id' argument")

        if 'bucket_width' in kwargs:
            unused_args.remove('bucket_width')
            _message.bucket_width = kwargs['bucket_width']

        if 'start' in kwargs:
            unused_args.remove('start')
            _message.start = kwargs['start']

        if 'end' in kwargs:
            unused_args.remove('end')
            _message.end = kwargs['end']

        if 'bucket_value_type' in kwargs:
            unused_args.remove('bucket_value_type')
            _message.bucket_value_type = kwargs['bucket_value_type']

        if 'read_length_type' in kwargs:
            unused_args.remove('read_length_type')
            _message.read_length_type = kwargs['read_length_type']

        if 'discard_outlier_percent' in kwargs:
            unused_args.remove('discard_outlier_percent')
            _message.discard_outlier_percent = kwargs['discard_outlier_percent']

        if len(unused_args) > 0:
            raise ArgumentError("get_read_length_histogram got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_read_length_histogram(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_read_length_histogram. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_read_length_types(self, _message=None, _timeout=None, **kwargs):
        """
        Gets a list of the types of read-length values for which a histogram is available

        Since 3.2

        :param run_id:
            The acquisition id of the experiment.  If this is not specifified, then it
            will be an empty string by default.  In this case, the current acquisition
            will be assumed.
        :rtype: GetReadLengthTypesResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_read_length_types(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_read_length_types. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetReadLengthTypesRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']

        if len(unused_args) > 0:
            raise ArgumentError("get_read_length_types got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_read_length_types(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_read_length_types. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_pore_speed_in_bases_boxplots(self, _message=None, _timeout=None, **kwargs):
        """
        Returns the speed by bases metric represented as datasets (i.e. boxplots).

        Speed by bases is the pore speed measured in called bases: read length in bases / read length in seconds
        for all the reads that were successfully called.

        A dataset is a collection of quantiles (min, max, q50 etc - please see BoxplotDataset) recorded for
        a fixed period of time, say dt. dt is specified in the configs, and it defaults to 10 min for MinKNOW 3.2.
        When acquisition starts, MinKNOW accumulates these stats for each dt interval. Each dt generates
        a dataset streamed by this rpc. The stream can request aggregated stats by averaging the stats from
        consecutive dt periods.

        Notes:

        Each streamed message will return ALL the datasets (i.e. boxplots) from the start of the experiment.

        When using this rpc, basecalling needs to be enabled.

        Since 3.2

        :param dataset_width:
            Defines, in minutes, the width of each dataset.
            This is how much time should each dataset (boxplot) cover. Note that MinKNOW stores
            all stats at a default granularity (specified in the config file, i.e. 10 min in MinKNOW 3.2).
            This dataset_width HAS to be a multiple of the default granularity!

            Note:
            When multiple buckets are aggregated into a single dataset, the resulting dataset will
            contain the average of the aggregated quantiles (with the exception of min/max)! This is not the
            same as using a larger granularity in MinKNOW configs - the values that MinKNOW stores
            are the true quantiles. Averaging quantiles will give a rough approximation, but not a quantile.
            If the finest granularity is not required, we strongly suggest changing the time coverage in the config,
            not the dataset_width in the rpc.
        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead of returning with an error

            Defaults to false
        :param poll_time:
            How often to return messages in this stream, specified in seconds. Note that this stream will
            return results regardless of the stats updates (because it always returns all the datasets).
            poll_time should be larger than the basecalled stats update rate in MinKNOW -
            please see basecalled_stats_refresh_rate_seconds in the configs
            (set to 1 second in MinKNOW 3.2).
        :rtype: BoxplotResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_pore_speed_in_bases_boxplots(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_pore_speed_in_bases_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamBoxplotRequest()

        if 'dataset_width' in kwargs:
            unused_args.remove('dataset_width')
            _message.dataset_width = kwargs['dataset_width']

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if 'poll_time' in kwargs:
            unused_args.remove('poll_time')
            _message.poll_time = kwargs['poll_time']

        if len(unused_args) > 0:
            raise ArgumentError("stream_pore_speed_in_bases_boxplots got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_pore_speed_in_bases_boxplots(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_pore_speed_in_bases_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_pore_speed_in_bases_boxplots(self, _message=None, _timeout=None, **kwargs):
        """
        Get the final representation of the speed by bases for a requested acquisition period.
        The acquisition must have finished at the time of this call, or the grpc will fail.

        Since 3.2

        :param run_id: (required)
            The acquisition id of the experiment.
        :param dataset_width:
            Defines, in minutes, the width of each dataset.
            This is how much time should each boxplot be covering. Note that MinKNOW stores
            all stats at the default granularity (specified in the config file, usually 10 min).
            This dataset_width HAS to be a multiple of the default granularity!

            Note:
            When multiple buckets are aggregated into a single dataset, the resulting dataset will
            contain the average of the aggregated quantiles! This is not the same value as
            using a larger granularity in MinKNOW configs - the values that MinKNOW stores
            are the true quantiles. Averaging quantiles will give a rough approximation, but not a quantile.
            If the finest granularity is not required, we suggest changing the value in the config,
            not the dataset_width in the rpc.
        :rtype: BoxplotResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_pore_speed_in_bases_boxplots(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_pore_speed_in_bases_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetBoxplotRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_pore_speed_in_bases_boxplots requires a 'run_id' argument")

        if 'dataset_width' in kwargs:
            unused_args.remove('dataset_width')
            _message.dataset_width = kwargs['dataset_width']

        if len(unused_args) > 0:
            raise ArgumentError("get_pore_speed_in_bases_boxplots got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_pore_speed_in_bases_boxplots(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_pore_speed_in_bases_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def stream_qscore_boxplots(self, _message=None, _timeout=None, **kwargs):
        """
        Returns the qscore over time metric represented as datasets (i.e. boxplots).

        This metric applies to all the successfully called reads.

        A dataset is a collection of quantiles (min, max, q50 etc - please see BoxplotDataset) recorded for
        a fixed period of time, say dt. dt is specified in the configs, and it defaults to 10 min for MinKNOW 3.2.
        When acquisition starts, MinKNOW accumulates these stats for each dt interval. Each dt generates
        a dataset streamed by this rpc. The stream can request aggregated stats by averaging the stats from
        consecutive dt periods.

        Notes:

        Each streamed message will return ALL the datasets (i.e. boxplots) from the start of the experiment.

        When using this rpc, basecalling needs to be enabled.

        Since 3.2

        :param dataset_width:
            Defines, in minutes, the width of each dataset.
            This is how much time should each dataset (boxplot) cover. Note that MinKNOW stores
            all stats at a default granularity (specified in the config file, i.e. 10 min in MinKNOW 3.2).
            This dataset_width HAS to be a multiple of the default granularity!

            Note:
            When multiple buckets are aggregated into a single dataset, the resulting dataset will
            contain the average of the aggregated quantiles (with the exception of min/max)! This is not the
            same as using a larger granularity in MinKNOW configs - the values that MinKNOW stores
            are the true quantiles. Averaging quantiles will give a rough approximation, but not a quantile.
            If the finest granularity is not required, we strongly suggest changing the time coverage in the config,
            not the dataset_width in the rpc.
        :param wait_for_processing:
            If `wait_for_processing` is true, then will wait until minknow starts acquiring data instead of returning with an error

            Defaults to false
        :param poll_time:
            How often to return messages in this stream, specified in seconds. Note that this stream will
            return results regardless of the stats updates (because it always returns all the datasets).
            poll_time should be larger than the basecalled stats update rate in MinKNOW -
            please see basecalled_stats_refresh_rate_seconds in the configs
            (set to 1 second in MinKNOW 3.2).
        :rtype: BoxplotResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.stream_qscore_boxplots(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_qscore_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = StreamBoxplotRequest()

        if 'dataset_width' in kwargs:
            unused_args.remove('dataset_width')
            _message.dataset_width = kwargs['dataset_width']

        if 'wait_for_processing' in kwargs:
            unused_args.remove('wait_for_processing')
            _message.wait_for_processing = kwargs['wait_for_processing']

        if 'poll_time' in kwargs:
            unused_args.remove('poll_time')
            _message.poll_time = kwargs['poll_time']

        if len(unused_args) > 0:
            raise ArgumentError("stream_qscore_boxplots got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.stream_qscore_boxplots(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.stream_qscore_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error

    def get_qscore_boxplots(self, _message=None, _timeout=None, **kwargs):
        """
        Get the final representation of the qscore over time metric for a requested acquisition period.
        The acquisition must have finished at the time of this call, or the grpc will fail.

        Since 3.2

        :param run_id: (required)
            The acquisition id of the experiment.
        :param dataset_width:
            Defines, in minutes, the width of each dataset.
            This is how much time should each boxplot be covering. Note that MinKNOW stores
            all stats at the default granularity (specified in the config file, usually 10 min).
            This dataset_width HAS to be a multiple of the default granularity!

            Note:
            When multiple buckets are aggregated into a single dataset, the resulting dataset will
            contain the average of the aggregated quantiles! This is not the same value as
            using a larger granularity in MinKNOW configs - the values that MinKNOW stores
            are the true quantiles. Averaging quantiles will give a rough approximation, but not a quantile.
            If the finest granularity is not required, we suggest changing the value in the config,
            not the dataset_width in the rpc.
        :rtype: BoxplotResponse
        """
        if _message is not None:
            if isinstance(_message, MessageWrapper):
                _message = _message._message
            retry_count = 20
            error = None
            for i in range(retry_count):
                try:
                    result = MessageWrapper(self._stub.get_qscore_boxplots(_message, timeout=_timeout), unwraps=[])
                    return result
                except grpc.RpcError as e:
                    # Retrying unidentified grpc errors to keep clients from crashing
                    if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                    (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                        logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_qscore_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                    else:
                        raise
                    error = e
                time.sleep(1)
            raise error

        unused_args = set(kwargs.keys())

        _message = GetBoxplotRequest()

        if 'run_id' in kwargs:
            unused_args.remove('run_id')
            _message.run_id = kwargs['run_id']
        else:
            raise ArgumentError("get_qscore_boxplots requires a 'run_id' argument")

        if 'dataset_width' in kwargs:
            unused_args.remove('dataset_width')
            _message.dataset_width = kwargs['dataset_width']

        if len(unused_args) > 0:
            raise ArgumentError("get_qscore_boxplots got unexpected keyword arguments '{}'".format("', '".join(unused_args)))
        retry_count = 20
        error = None
        for i in range(retry_count):
            try:
                result = MessageWrapper(self._stub.get_qscore_boxplots(_message, timeout=_timeout), unwraps=[])
                return result
            except grpc.RpcError as e:
                # Retrying unidentified grpc errors to keep clients from crashing
                if (e.code() == grpc.StatusCode.UNKNOWN and "Stream removed" in e.details()) or\
                (e.code() == grpc.StatusCode.INTERNAL and "RST_STREAM" in e.details()):
                    logging.info('Bypassed ({}: {}) error for grpc: ont.rpc.statistics.StatisticsService.get_qscore_boxplots. Attempt {}.'.format(e.code(), e.details(), i))
                else:
                    raise
                error = e
            time.sleep(1)
        raise error


